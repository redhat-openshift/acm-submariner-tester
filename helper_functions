#!/bin/bash
# shellcheck disable=SC2153,SC2031,SC2016,SC2120,SC2005,SC1091

### General Library of helper functions ###

### Constants ###

# Console print colors
export RED='\x1b[0;31m'
export GREEN='\x1b[38;5;22m'
export CYAN='\x1b[36m'
export YELLOW='\x1b[33m'
export NO_COLOR='\x1b[0m'
export HAT="${RED}ðŸŽ©ï¸Ž${NO_COLOR}"

# Conda environment test directory
export CONDA_ENV_NAME="${CONDA_ENV_NAME:-conda-test}"
export CONDA_CMD="conda"

# Set SCRIPT_DIR as current absolute path where this script runs in
SCRIPT_DIR="$(dirname "$(realpath -s "$0")")"
export SCRIPT_DIR

# include sh2ju library
source "$SCRIPT_DIR/lib/sh2ju.sh"

shopt -s nocasematch # Case-insensitive match for string evaluations

set -o allexport # To export each function when it is declared, to be used on external bash processes

### Functions ###

# ------------------------------------------

function print_all_env_variables() {
### Helper function to print all environment variables (excluding key|sec|pas|pwd)###
  trap_to_debug_commands;

  TITLE "List all environment variables"

    # List all variables
    compgen -v | sort | \
    while read var_name; do
      # Get each variable value
      var_value="${!var_name}"
      # If variable is not null or contains "key" / "sec"ret / "pas"sword
      if ! [[ -z "$var_value" || "$var_name" =~ (key|sec|pas|pwd) ]] ; then
        # Trim value (string), if it is longer than 500 char
        (( ${#var_value} < 500 )) || var_value="${var_value:0:500}..."
        # Print the value without non-ascii chars
        echo -e "$var_name = $var_value" | tr -dC '[:print:]\t\n'
      fi
    done

}

# ------------------------------------------

# Function to search and highlight rexexp in file (or pipe content)
function highlight()
{
  #trap_to_debug_commands
  pattern="$1"
  file_input="$2"

  exit_code=0
  # 0 = Match found
  # 1 = SED execution error
  # 3 = Match not found
  # 4 = Empty string or file

  local tmp_file
  tmp_file="$(mktemp)_highlight"
  # Save all output to temp file
  #grep -E "$pattern|$" "$@" > $tmp_file
  grep -Ei "$pattern|$" ${file_input:+"$file_input"} > "$tmp_file"

  # Exit if file is empty or contains spaces only
  grep -q '[^[:space:]]' "$tmp_file" || return 4

  # Print with match colored
  # cat $tmp_file | grep --color -E "$pattern|$"

  # Search line for sed command. Highlighting pattern, if found
  search_line='/'"$pattern"'/I,${s//'$YELLOW'&'$NO_COLOR'/g;b};$q3'

  # SED with -r : Basic regex
  sed -r "$search_line" "$tmp_file" || exit_code=$?

  # If SED had an error, try to search with -e : Extended regex"
  if [[ "$exit_code" -eq 1 ]] ; then
    exit_code=0
    sed -e "$search_line" "$tmp_file" || exit_code=$?
  fi

  # Return if match found
  # cat $tmp_file | grep -q -E "$pattern"
  return $exit_code
}

# ------------------------------------------

function print_current_dir_and_cmd() {
  # Print called command and current directory
  # Important: Use _unique_ variables for safer evaluation

  local _bash_cmd
  # Trim leading and trailing spaces from command
  _bash_cmd="$(echo $1)"
  # Skip printing if it's an empty command
  [[ -n "$_bash_cmd" ]] || return

  # Print PS1 prompt with location (if it's new location)
  local _new_location="[$0] $PS1 [${PWD##*/}]" && \
  if [[ "$_new_location" != "$_current_location" ]]; then
    export _current_location="$_new_location"
    echo -e "\n${YELLOW}$_current_location${NO_COLOR}\n"
  fi

  # Save all command variables' values inside $_all_vars_output
  local _all_vars_output="\n"

  # List simple variables ($v or ${v}) first
  local _var_list
  _var_list=( $(echo "$_bash_cmd" | grep -ohP "\\\$\w+|\\\$\{\w+\}" | sort -u) ) || return

  # List complex variables (with parameter expansion) next
  _var_list+=( $(echo "$_bash_cmd" | grep -ohP "\\\$\{\w+[:/][^\}]+\}" | sort -u) ) || return

  for variable in "${_var_list[@]}" ; do
    local _var_name
    _var_name="$(echo "${variable%%[:/]*}" | tr -dc '[a-zA-Z_0-9]' || : )"
    [[ -n "$_var_name" ]] || continue

    local _var_value
    _var_value="$(echo "${!_var_name}" 2>/dev/null || : )"
    [[ -n "$_var_value" ]] || continue

    if [[ "$variable" =~ [:/] ]] ; then
     # For complex variables - add it to $_all_vars_output
     _all_vars_output+="\$ ${_var_name}=${_var_value} \n" || continue
    else
     # For simple variables - replace them with their values within $_bash_cmd
     _bash_cmd="${_bash_cmd//$variable/$_var_value}" || continue
    fi
  done

  # Print $_all_vars_output (after # sign), and $_bash_cmd (after $ sign)
  echo -e "${CYAN}${_all_vars_output}\$ ${_bash_cmd}${NO_COLOR}"
}

# ------------------------------------------

# Function to print each bash command before it is executed (using with "set -T" might have issues)
function trap_to_debug_commands() {
  trap '
   if [[ ! "$BASH_COMMAND" =~ ^(echo|read|PROMPT|TITLE|BUG|FATAL|FAILURE) ]] ; then
      set +e
      print_current_dir_and_cmd "$BASH_COMMAND"
      set -e
   fi
  ' DEBUG
}

# ------------------------------------------

# Function to trap test exit failure - to print more info before exiting main flow
function trap_function_on_error() {
  trap '' DEBUG # DONT trap_to_debug_commands

  local func_on_script_error="${1}"
  local test_status_file="${2}" # Optional: exit code will be set by this file (instead of fuction RC)

  # If other traps already set - make sure to execute it after $func_on_script_error
  current_traps="$(trap -p EXIT | tr '\n' ' :; ' | cut -f2 -d \')"

  trap_cmd='rc=$?; echo -e "\n# $FUNCNAME[$@] returned EXIT $rc:
  ${BASH_SOURCE[$i+1]}:$BASH_LINENO > ${BASH_SOURCE[$i]}:${BASH_LINENO[$i-1]}" ;
  [[ ! -s '$test_status_file' ]] || rc=$(< '$test_status_file') || : ;
  [[ "$rc" == "0" ]] || ('${func_on_script_error}') || : ;
  [[ -z "'${current_traps}'" ]] || ('${current_traps}') || : ;'

  echo -e "\n# Trapping on script EXIT: \n${trap_cmd} \n"
  trap '(exit 130)' INT # When SIGINT is received call $trap_cmd
  trap '(exit 143)' TERM # When SIGTERM is received call $trap_cmd
  trap "$trap_cmd" EXIT
}

# ------------------------------------------

# function to watch for expected regex of command output, with retry attempts or timeout
function watch_and_retry() {
  # Do not trap_to_debug_commands

  # Param 1: Command to execute and watch
  CMD="$1"
  # Param 2 (Optional): Number of retry attempts (default is 10)
  RETRY="${2:-10}" # If adding s/m to the number, it will be timeout in seconds/minutes
  # Param 3 (Optional): Pattern to search, otherwise expect $CMD exit 0
  REGEX="$3"

  # Max timeout for the whole watch process (default is 10 minutes)
  TIMEOUT=10m

  # echo -e "# Watching output of command: $(eval echo \"$CMD\") \
  # echo -e "# Watching output of command: $CMD"

  # Set timeout for the whole process, if RETRY is number of seconds/minutes (e.g. 20s or 3m)
  if [[ "$RETRY" =~ [0-9]+[sm] ]] ; then
    TIMEOUT=$RETRY
    RETRY=-1
  fi

  echo -e "Watching output of command...
  \n Retry attempts: $RETRY
  \n Timeout limit: $TIMEOUT"

  # If REGEX was specified - will wait for REGEX to be found in CMD output
  if [[ -n "$REGEX" ]] ; then
    echo "Search pattern: $REGEX"
    CMD="( $CMD ) | highlight '$REGEX'"
  fi

  # To use timeout - must run command as an external script
  timeout "$TIMEOUT" bash <<EOF \
  || ( [[ $? -eq 124 ]] && echo "Timeout of $TIMEOUT has exceeded." && return 1 )
    COUNT=0 ;
    until $CMD || [[ \$COUNT -eq $RETRY ]] ; do
      printf "\$(( COUNT++ ))... " ;
      sleep 1 # A second interval ;
    done
    if [[ \$COUNT -eq $RETRY ]]; then
      echo "Limit of $RETRY attempts has exceeded." ;
      exit 1 ;
    fi ;
    exit 0 ;
EOF
}

# ------------------------------------------

# function to run command with timeout, and tail log in parallel
function run_and_tail() {
  trap_to_debug_commands

  # Param 1: Command to execute
  local cmd="$1"
  # Param 2: Log file to tail
  local log_to_tail="$2"
  # Param 3: timeout duration (default 1 hour)
  local duration="${3:-1h}"
  # Param 4: RegEx to find in log (if not given, return process exit code)
  local regex="$4"

  echo -e "Running command as background process: $cmd
  \n Timeout duration: $duration
  \n Tailing log file: $log_to_tail"

  # Running the process with timeout - in the background, and store its PID
  timeout --foreground "$duration" $cmd &
  local pid=$!
  local process_rc=0

  # Tail the log, until command has ended or timed-out
  mkdir -p "$(dirname "$log_to_tail")"
  touch "$log_to_tail"
  tail --pid=$pid -n0 -F "$log_to_tail" | sed 's/\\n/\n/g'

  # Check the exit code of the command PID
  wait $pid || process_rc="$?"

  if [[ "$process_rc" == 124 ]] ; then
    echo -e "\n# Timeout of $duration has exceeded while running [$cmd]"
  elif [[ "$process_rc" != 0 ]] ; then
    echo -e "\n# Command [$cmd] has failed (Error $process_rc)"
  fi

  if [[ -n "$regex" ]] ; then
    # When searching for regex in log, it will ignore cmd exit code
    process_rc=0
    grep "$regex" "$log_to_tail" || process_rc="$?"
    [[ "$process_rc" == 0 ]] || \
    echo -e "\n# The expected search pattern '$regex' was not written to the log file [$log_to_tail]"
  fi

  return $process_rc
}

# ------------------------------------------

# Function to print highlighted message with the current time
function PROMPT() {
  local message="$1"
  local color="${2:-${YELLOW}}"
  local cur_time
  cur_time="$(date '+%Y-%m-%d %H:%M:%S' || :)"

  echo -e "\n${HAT}[${cur_time}]\n"\
  "${color}### ${message} ###${NO_COLOR}\n"\
  "[${PWD}]\n"
}

# ------------------------------------------

# Function to message as a title inside #####
function TITLE() {
  local message="$1"
  local color="${2:-${YELLOW}}"

  local first_line
  first_line="$(echo -e "${message}" | head -1)"

  local line_length=$(( ${#first_line} + 15 ))
  local color_line
  color_line="${color}$( printf '%0.s#' $(seq 1 $line_length) )${NO_COLOR}"
  local color_char="${color}#${NO_COLOR}"

  # Print first line of message in color # box
  echo
  echo -e "$color_line"
  echo -e "$color_char       $first_line      $color_char"
  echo -e "$color_line"

  # Print rest of message (from line 2), with # at the beginning
  echo -e "${message}" | tail -n +2 | sed 's/^/# /'
  echo

}

# ------------------------------------------

# Function to print FAILURE message and return 5 for the current test
# sh2ju treats exit code 5 as non-critical failure (to continue tests)
function FAILURE() {
  local failure_msg="${1}"
  echo -e "\n${RED}*** Test failure occurred *** \n $failure_msg ${NO_COLOR}" >&2
  return 5
}

# ------------------------------------------

# Function to print FATAL message and exit the whole test suite
function FATAL() {
  local failure_msg="${1}"
  echo -e "\n${RED}*** Fatal error occurred *** \n $failure_msg ${NO_COLOR}" >&2
  # kill -s TERM $$
  # kill -s TERM $BASHPID
  # kill -s EXIT $PPID
  return 127
}

# ------------------------------------------

# Function to print message about a potential bug/workaround, and an optional bug link
function BUG() {
  failed_action="${1}"
  workaround="${2}" # optional
  bug_ref="${3}" # optional

  echo -e "${RED}****** BUG ******\n Failure:${NO_COLOR} $failed_action"
  [[ -z "$workaround" ]] || echo -e "${RED} Workaround:${NO_COLOR} $workaround"
  [[ -z "$bug_ref" ]] || echo -e "${RED} Reference:${NO_COLOR} $bug_ref"
}

# ------------------------------------------

# Function to check if version (e.g. v2.5) is greater or equal to another version (e.g. v2.4.1)
function check_version_greater_or_equal() {
  # If version input $1 is lower than version input $2 (digits and dots only), then the returned exit code will be 1
  printf '%s\n%s\n' "${2//[!0-9.]/}" "${1//[!0-9.]/}" | sort --check=quiet --version-sort
}

# ------------------------------------------

# Function to run the command and records its output/error messages in junit format
# Ref: https://github.com/kubernetes/kubernetes/blob/master/test/cmd/legacy-script.sh
function record_junit() {
  # it expects the first to be the name of the command
  # Example:
  # record_junit function_name arg1 arg2
  #
  # WARNING: Variable changes in the command will NOT be effective after record_junit returns.
  #          This is because the command runs in subshell.

  # $1 => $junit_output_file and $output_dir for junit results
  local junit_output_file
  junit_output_file=$(basename "$1")

  local output_dir
  output_dir=$(dirname "$1")

  # Shift input arguments counter
  local shift_arg_counter=1

  if [[ -f "${2}" ]] ; then
    # $2 is a file representing the test suite status: Overall test run status, stored in a file.
    # It can include either 0 (OK to continue tests), 1 (Critical failure: Skip rest of tests), 2 (Failed but continue)
    local test_status_file="${2}"

    # Shifting input arguments should be done twice
    shift_arg_counter=2
  fi

  # Shift input arguments to the left, in order to collect the rest of arguments as an array
  shift $shift_arg_counter

  # Save rest of input args as an array
  local func_and_args="$*"

  # Set junit test name as the called function and args (omitting special characters)
  local test_name="${func_and_args//[^a-zA-Z0-9 -\/]/_}"

  # Set junit_suite as the base directory name of $output_dir
  local junit_suite
  junit_suite="$(basename "$output_dir")"

  echo "+++ Recording test as Junit: ${func_and_args}"
  echo "+++ XML output of all Junit: ${output_dir}/${junit_output_file}"
  echo "+++ Using test status file:  ${test_status_file}"

  juLog -output="$output_dir" -file="$junit_output_file" -index -class="$junit_suite" -name="$test_name" ${test_status_file:+-status="$test_status_file"} "$func_and_args"
}

# ------------------------------------------

# Function to installing Anaconda (https://github.com/conda-forge)
function install_anaconda() {
  # trap_to_debug_commands
  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  miniconda_bin_dir="${conda_install_dir}/bin"
  conda_env="${CONDA_ENV_NAME}${WORKDIR:+-${WORKDIR##*/}}"
  [[ ":$PATH:" != *"/miniconda/bin:"* ]] && export PATH=${miniconda_bin_dir}:$PATH

  if ${CONDA_CMD} env list | grep -o "^$conda_env" | grep . ; then
    echo -e "\n# Anaconda is already installed and has environment '$conda_env' configured"
    ${CONDA_CMD} info
    ${CONDA_CMD} update -n base -c defaults conda -y
    source activate "$conda_env"
    return
  fi

  if ${CONDA_CMD} info ; then
    # Clean previous ${CONDA_CMD} packages
    ${CONDA_CMD} clean -y --all
    # rm -rf "${conda_install_dir}" || :
  fi

  echo -e "\n# Installing Anaconda"
  # curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj ${miniconda_bin_dir}/micromamba
  # conda install mamba -n base -c conda-forge

  miniconda_installer="Miniconda3-latest-Linux-x86_64.sh"
  download_file "https://repo.anaconda.com/miniconda/${miniconda_installer}" "${work_dir}/${miniconda_installer}"
  chmod +x "${work_dir}/${miniconda_installer}"
  "${work_dir}"/${miniconda_installer} -b -u -p "${conda_install_dir}"
  conda update -y -n base -c defaults conda

  # Remove old ${CONDA_CMD} environment dir, if it is not configured
  env_dir=$(${CONDA_CMD} env list | awk -v name="$conda_env" '$0 ~ name { print $2 }')
  env_base=$(${CONDA_CMD} env list | awk '/base/ { print $NF }')

  if [[ -z "$env_dir" ]] ; then
    echo -e "\n# Removing old Conda environment \"$conda_env\" directory (since it is not configured):"
    ${CONDA_CMD} env remove -y -n "$conda_env" || :
    ${CONDA_CMD} env remove -y -p "$env_base/envs/$conda_env" || :
    rm -rf "$env_base/envs/$conda_env" || :
  fi

  echo -e "\n# Creating Conda environment \"$conda_env\" (if it does not exist already)"
  [[ -d "$env_base/envs/$conda_env" ]] || ${CONDA_CMD} create -y -n "$conda_env"
}

# ------------------------------------------

# Function to verify Anaconda installation
function verify_anaconda() {
  trap_to_debug_commands
  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  miniconda_bin_dir="${conda_install_dir}/bin"
  conda_env="${CONDA_ENV_NAME}${WORKDIR:+-${WORKDIR##*/}}"
  [[ ":$PATH:" != *"/miniconda/bin:"* ]] && export PATH=${miniconda_bin_dir}:$PATH

  ${CONDA_CMD} info
  ${CONDA_CMD} env list | grep "miniconda/envs/${conda_env}"
}

# ------------------------------------------

# Function to install local tool/package with Anaconda (https://github.com/conda-forge/{package name})
function install_conda_package() {
  # trap_to_debug_commands

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  local pkg_name="$2"
  local pkg_version="$3"
  local pkg_label="$4"

  echo -e "\n# Installing a local tool [${pkg_name}${pkg_version:+=$pkg_version}] with Anaconda, in \"$(whoami)\" home directory."

  local conda_env="${CONDA_ENV_NAME}${WORKDIR:+-${WORKDIR##*/}}"

  if ${CONDA_CMD} list | grep -Eo "${pkg_name}\s+${pkg_version//./\\.}\s+" ; then
    echo -e "\n# Package '${pkg_name}' ${pkg_version:+=(version ${pkg_version})} is already installed in ${CONDA_CMD} environment '$conda_env'"
    return
  fi

  local conda_pkg_status
  verify_anaconda "${conda_install_dir}"

  # ${CONDA_CMD} config --add channels defaults
  ${CONDA_CMD} config --add channels conda-forge
  ${CONDA_CMD} deactivate
  ${CONDA_CMD} install -y --update-deps -c conda-forge${pkg_label:+/label/$pkg_label} -n "${conda_env}" "${pkg_name}${pkg_version:+=$pkg_version}" || conda_pkg_status=FAILED
  source activate "$conda_env"

  if [[ "$conda_pkg_status" != FAILED ]] ; then
    ${CONDA_CMD} list
  else
    return 1
  fi
}

# ------------------------------------------

# Function to install local Golang with Anaconda (https://github.com/conda-forge/go-nocgo_linux-64)
function install_local_golang() {
  # trap_to_debug_commands

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  local pkg_version="$2"

  install_conda_package "${conda_install_dir}" "go-nocgo_linux-64" "${pkg_version}"
}

# ------------------------------------------

# Function to verify that Golang is installed
function verify_golang() {
  echo -e "\n# Verifying Golang installation, and setting GOROOT, GOPATH, GOBIN, and GO111MODULE=on"
  go version

  # export GOROOT=/usr/local/go
  GOROOT=$(go env GOROOT)
  export GOROOT

  # export GOPATH=~/go
  GOPATH=$(go env GOPATH)
  export GOPATH

  # Optional: exporting $1 as GOBIN path
  # export GOBIN="${1:-$GOROOT/bin}"

  # export PATH=$PATH:$GOROOT/bin
  [[ ":$PATH:" != *":$GOBIN:"* ]] && export PATH=$GOBIN:$PATH

  export GO111MODULE=on

  # Print all GO env variables
  go env
}

# ------------------------------------------

# Function to install local Terraform with Anaconda (https://anaconda.org/conda-forge/terraform)
function install_local_terraform() {
  # trap_to_debug_commands

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  local pkg_version="$2"

  install_conda_package "${conda_install_dir}" "terraform" "${pkg_version}"
}

# ------------------------------------------

# Docker with Anaconda is not supported in Linux yet - use Podman instead
# Function to install local Docker with Anaconda (https://anaconda.org/conda-forge/docker)
function install_local_docker() {
  trap_to_debug_commands
  # curl -o /etc/yum.repos.d/vbatts-shadow-utils-newxidmap-epel-7.repo \
  # https://copr.fedorainfracloud.org/coprs/vbatts/shadow-utils-newxidmap/repo/epel-7/vbatts-shadow-utils-newxidmap-epel-7.repo
  # yum install -y shadow-utils46-newxidmap
  # SKIP_IPTABLES=1 curl -fsSL https://get.docker.com/rootless | sh -s -- --experimental
  # # curl -fsSL https://get.docker.com/rootless | sh -s -- --iptables=false

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  local pkg_version="$2"

  install_conda_package "${conda_install_dir}" "docker" "${pkg_version}"
}

# ------------------------------------------

# Function to install local Podman with Anaconda (https://anaconda.org/conda-forge/podman)
function install_local_podman() {
  trap_to_debug_commands

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  local pkg_version="$2"

  install_conda_package "${conda_install_dir}" "podman" "${pkg_version}"
}

# ------------------------------------------

# Function to install local JQ with Anaconda (https://anaconda.org/conda-forge/jq)
function install_local_jq() {
  # trap_to_debug_commands

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  local pkg_version="$2"

  install_conda_package "${conda_install_dir}" "jq" "${pkg_version}"

}

# ------------------------------------------

# Function to install gcloud cli with Anaconda (https://anaconda.org/conda-forge/google-cloud-sdk)
function install_local_gcloud() {
  # trap_to_debug_commands

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  local pkg_version="$2"

  local conda_env="${CONDA_ENV_NAME}${WORKDIR:+-${WORKDIR##*/}}"

  # export CLOUDSDK_PYTHON=/usr/bin/python2

  install_conda_package "${conda_install_dir}" "google-cloud-sdk" "${pkg_version}"

  # verify_anaconda "${conda_install_dir}"
  # source activate "$conda_env"
  # ${CONDA_CMD} install -y -c conda-forge google-cloud-sdk
  # ${CONDA_CMD} install -y -c conda-forge/label/cf201901 google-cloud-sdk
  # ${CONDA_CMD} install -y -c conda-forge/label/cf202003 google-cloud-sdk

  gcloud --version

}

# ------------------------------------------

# Function to convert raw text (e.g. yaml) to encoded url format
function raw_to_url_encode() {

  local string
  string="$(cat < /dev/stdin)"
  local strlen=${#string}
  local encoded=""
  local pos c o

  for (( pos=0 ; pos<strlen ; pos++ )); do
     c=${string:$pos:1}
     case "$c" in
        [-_.~a-zA-Z0-9] ) o="${c}" ;;
        * )               printf -v o '%%%02x' "'$c"
     esac
     encoded+="${o}"
  done

  echo "${encoded}"

}

# ------------------------------------------

# Function to download particular file or directory from particular Github commit or branch
function download_github_file_or_dir() {
  trap_to_debug_commands

  local git_user="$1"
  local git_project="$2"
  local commit_or_branch="${3:-master}" # default is master branch
  local dir_or_file="$4" # default is whole project tree

  archive_url="https://github.com/${git_user}/${git_project}/archive/${commit_or_branch}.tar.gz"

  echo -e "\n# Downloading from Github project: ${git_user}/${git_project} \
  ${commit_or_branch:+\n# Commit ID: $commit_or_branch} \
  \n# Directory: ${dir_or_file:-Whole project tree} \n"

  # Use WGET with a random wait of 5 to 15 seconds between retrievals, and resume getting a partially-downloaded file
  wget --wait 10 --random-wait --continue -O - "${archive_url}" \
  | tar xz --strip=1 "${git_project}-${commit_or_branch}/${dir_or_file}"

}

# ------------------------------------------

# Function to download file from URL, if local file doesn't exists, or has a different size on URL
function download_file() {
  trap_to_debug_commands
  # $1 => $source_file (download link)
  source_file="$(echo $1)" # Trim leading and trailing spaces

  # Optional: $2 => $target_file (where to save)
  target_file="${2:-$(basename "$1")}"

  TITLE "Downloading [$source_file] into $target_file"
  ls -ld

  local_file_size="$([[ -f ${target_file} ]] && wc -c < "${target_file}" || echo "0")"
  echo "local_file_size = $local_file_size"
  remote_file_size="$(curl -sI "${source_file}" | awk '/Content-Length/ { print $2 }' | tr -d '\r' )"
  echo "remote_file_size = $remote_file_size"
  [[ -n "$remote_file_size" ]] || remote_file_size=-1
  if [[ "$local_file_size" -ne "$remote_file_size" ]]; then
      echo -e "\n# Requested file was not downloaded yet, or remote file size is different. Downloading..."
      rm -rf "$target_file"
      if [[ -x "$(command -v wget)" ]] ; then
        target_dir="$(dirname -- "$target_file")"
        wget "$source_file" --no-verbose --no-check-certificate --directory-prefix="$target_dir"
        source_file="$(basename -- "$source_file")"
        [[ "$target_dir/$source_file" -ef "$target_file" ]] || mv -v "$target_dir/$source_file" "$target_file"
      else
        echo -e "\n# Wget is not installed, using Curl instead."
        curl -L "$source_file" -o "$target_file" --create-dirs
      fi
  else
    echo -e "\n# $target_file already downloaded, and equals to remote file $source_file"
  fi
}

# ------------------------------------------

# Function to delete files/directories which were not accessed N days (no recursive search in sub directories)
function delete_old_files_or_dirs() {
  trap_to_debug_commands
  # Input $1 : $wildcard_name
  wildcard_name="$1"

  # Input $2 (Optional) : $dir_or_file. f=file, d=directory (default)
  dir_or_file="${2:-f}"

  # Input $3 (Optional) : $access_days (default=5)
  access_days="${3:-5}"

  # Set $search_path as parent directory of $wildcard_name, if it includes slashes (current path by default)
  search_path=$(dirname -- "$wildcard_name")

  # Set $search_name as base directory of $wildcard_name, if it includes slashes
  search_name=$(basename -- "$wildcard_name")

  # find "$search_path"/* -maxdepth 0 -type $dir_or_file -name "$search_name" -atime +${access_days} -print -delete
  find "$search_path"/* -maxdepth 0 -type "$dir_or_file" -name "$search_name" -atime +"${access_days}" | xargs -n1 --verbose rm -rf
}

# ------------------------------------------

# Function to move non-empty directory to an existing directory
function backup_and_remove_dir() {
  trap_to_debug_commands
  # Input $1 : $src_dir
  src_dir="$1"

  # Input $2 (Optional) : $dest_dir
  dest_dir="${2:-_$1}"

  if [[ ! -d ${src_dir} ]] || [[ -z $(ls -A "$src_dir") ]] ; then
    echo -e "\n# Source directory [${src_dir}] doesn't exist (or empty). Skipping backup"
  else
    echo -e "\n# Backup directory [${src_dir}] into [${dest_dir}]"
    # Make a new directory (skip if exists)
    mkdir -p "$dest_dir"

    # Copy * from src_dir to dest_dir (-afr : Keep attributes, Force overwrite, Recursive copy)
    cp -afr "${src_dir}"/. "${dest_dir}"/

    # Force remove old directory
    lsof +D "$src_dir" | awk '{print $2}' | tail -n +2 | xargs --no-run-if-empty kill -9 || :
    rm -rf "$src_dir"
  fi
}

# ------------------------------------------

# Function to change value of a key, in a YAML file:
function change_yaml_key_value() {
  local yaml_file="$1"
  local key_name="$2"
  local new_value="$3"
  local section="$4" # optional section that the key is underneath

  echo -e "\n# Modifying YAML file [$yaml_file]: Key [$key_name] => Value [$new_value] ${section:+, under [$section].}"

  local section="${section:-.*}" # section default value is any string

  # sed -r "s/^(\s*${key}\s*:\s*).*/\1${new_value}/" -i "$yaml_file"

   echo "$(awk \
     -v key="(^[ \t]*(- )?${key_name}[ \t]*:?)(.*)$" \
     -v value="${new_value}" \
     -v section="${section}" \
     '
      BEGIN {
       done=0
       }
      {
         if (!done && $0 ~ section) {
           ++section_found
           key_found=0
         }
         replace = gensub(key, "\\1 "value, "g")
         if ($0 ~ key && replace) {
           ++key_found
         }
         if (!done && section_found>0 && key_found>0) {
           $0=replace
           done=1
         }
         print $0
       } ' "$yaml_file" \
    )" > "$yaml_file"
}

# ------------------------------------------

# Function to install gcloud CLI, and configure GCP (Google Cloud Platform) access:
function configure_gcp_access() {
  local gcp_cred_json="$1"

  if ! jq . "$gcp_cred_json" 1>/dev/null ; then
    FAILURE "JQ is not installed, or file '${gcp_cred_json}' is not in JSON format"
  fi

  work_dir="$(echo "${2:-$PWD}" | tr -s /)" # Remove redundant slashes

  install_local_gcloud "$work_dir"

  trap '' DEBUG # DONT trap_to_debug_commands

  export CLOUDSDK_PYTHON=/usr/bin/python2
  export GOOGLE_CREDENTIALS="${gcp_cred_json}"

  # local client_id
  # client_id=$(grep -Po 'client_id[^\d]*\K\d+' "${gcp_cred_json}")

  gcloud auth activate-service-account "$client_id" --key-file="${gcp_cred_json}"
  # gcloud config set project my-project
  # gcloud config set compute/zone us-east1

  gcloud auth list --filter=status:ACTIVE --format="value(account)"

}

# ------------------------------------------

# Function to install aws-cli, and to configure AWS access:
function configure_aws_access() {
  trap '' DEBUG # DONT trap_to_debug_commands

  local aws_profile_name="$1"
  local aws_region="$2"
  local aws_key="$3"
  local aws_secret="$4"
  local aws_install_dir="${5:-./}"
  local aws_bin_dir="${6:-$HOME/.local/bin}"

  install_awscli "$aws_install_dir" "$aws_bin_dir"

  (
    # subshell to hide commands
    aws configure set profile "$aws_profile_name"
    aws configure set aws_access_key_id "$aws_key"
    aws configure set aws_secret_access_key "$aws_secret"

    aws configure set default.region "$aws_region"
    aws configure set output text
    aws configure set color on
  )

  # aws --profile "$aws_profile_name" configure  --region "$aws_region" --output text --color on
  aws sts get-caller-identity
}

# ------------------------------------------

# Function to install aws-cli
function install_awscli() {
  # trap_to_debug_commands

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  aws_bin_dir="${2:-$(dirname "$work_dir")/miniconda}"

  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  if [[ ! -x "$(command -v aws)" ]] ; then
    echo -e "\n# Installing AWS-CLI tool with Anaconda"

    # {
    #   verify_anaconda "${conda_install_dir}" && \
    #   source activate "$conda_env" && \
    #   ${CONDA_CMD} install -y -c conda-forge awscli && \
    #   ${CONDA_CMD} install -y -c conda-forge/label/gcc7 awscli && \
    #   ${CONDA_CMD} install -y -c conda-forge/label/broken awscli && \
    #   ${CONDA_CMD} install -y -c conda-forge/label/cf201901 awscli && \
    #   ${CONDA_CMD} install -y -c conda-forge/label/cf202003 awscli
    #
    # } || CONDA_PKG=FAILED

    install_conda_package "${conda_install_dir}" "awscli" || CONDA_PKG=FAILED

    if [[ "$CONDA_PKG" == FAILED ]] ; then
      TITLE "Installing AWS-CLI with Anaconda failed - trying to download and install aws-cli from zip"

      if [[ ! -x "$(command -v unzip)" ]] ; then
        echo -e "\n# Installing unzip tool"
        # ${CONDA_CMD} install -y -c conda-forge unzip
        # ${CONDA_CMD} install -y -c conda-forge/label/cf201901 unzip
        # ${CONDA_CMD} install -y -c conda-forge/label/cf202003 unzip
        install_conda_package "${conda_install_dir}" "unzip"
      fi

      aws_cli_installer="awscli-exe-linux-x86_64.zip"
      download_file "https://awscli.amazonaws.com/${aws_cli_installer}" "${work_dir}/${aws_cli_installer}"
      unzip -n "${work_dir}/${aws_cli_installer}" -d "${work_dir}"

      [[ ":$PATH:" != *":${aws_bin_dir}:"* ]] && export PATH="${PATH}:${aws_bin_dir}"
      "${work_dir}/aws/install" --update --install-dir "${work_dir}/aws" --bin-dir "${aws_bin_dir}"
    fi
  fi

  aws --version
}

# ------------------------------------------

# Function to create json file for a DNS record deletion on AWS
function create_json_for_dns_delete() {
  # Input $1 : File to write the json output to
  (
  cat <<EOF
  {
      "Comment": "Delete single record set",
      "Changes": [
          {
              "Action": "DELETE",
              "ResourceRecordSet": {
                  "Name": "${Name/\\052/*}",
                  "Type": "$Type",
                  "AliasTarget": {
                    "HostedZoneId": "$HostedZoneId",
                    "DNSName": "$DNSName",
                    "EvaluateTargetHealth": $EvaluateTargetHealth
                    }}
                }]
    }
EOF
  ) > "$1"
}

# ------------------------------------------

# Function to export variables from json file as environment variables
function export_vars_from_json() {
  # Input $1 : Json file to read variables from
  for s in $(grep -E '": [^\{]' "$1" | sed -e 's/: /=/' -e 's/^\s*//' -e "s/\(\,\)$//"); do
    echo -e "\n# export $s"
    eval export "$s"
  done
}

# ------------------------------------------

# Function to delete an DNS record set in AWS Hosted Zone
function delete_aws_dns_records() {
  trap_to_debug_commands;
  local hosted_zone_id="$1"
  local dns_record_set="$2"
  local tmp_file
  tmp_file="$(mktemp)_aws_records"

  echo -e "\n# Searching in Hosted Zone [$hosted_zone_id] - for a DNS record set: [$dns_record_set]"
  aws route53 list-resource-record-sets --hosted-zone-id "$hosted_zone_id" --query "ResourceRecordSets[?Name == '$dns_record_set']" --out json > "$tmp_file"

  cat "$tmp_file"

  if [[ $(< "$tmp_file") == '[]' ]]; then
    echo -e "The DNS record set does not exist in AWS cluster [${CLUSTER_A_NAME}]"
    return
  fi

  echo -e "\n# Exporting DNS record set variables:"
  export_vars_from_json "$tmp_file"

  echo -e "\n# Creating json file for the DNS record set delete command:"
  create_json_for_dns_delete "$tmp_file"
  cat "$tmp_file"

  echo -e "\n# Deleting the DNS record set:"
  aws route53 change-resource-record-sets --hosted-zone-id "$hosted_zone_id" --change-batch "file://$tmp_file"

}

# ------------------------------------------

# Function to login to OCP server
function ocp_login() {

  # Optional inputs: $ocp_usr, $ocp_pwd, $ocp_server

  local ocp_usr
  ocp_usr="${1:-$(${OC} whoami | tr -d ':')}"

  local ocp_pwd

  local ocp_server
  ocp_server="${3:-$(${OC} config view -o jsonpath='{.clusters[].cluster.server}')}"

  local cluster_name
  cluster_name="$(print_current_cluster_name || :)"

  local ocp_cloud
  ocp_cloud="$(print_current_cluster_cloud || :)"

  if [[ -z "${ocp_server}" || -z "${ocp_usr}" ]] ; then
    FAILURE "User '${ocp_usr}' or Server '${ocp_server}' is missing"
  fi

  TITLE "Login with user ${ocp_usr} to OCP server '${cluster_name}' on ${ocp_cloud} cloud:
  ${ocp_server}"

  ( # subshell to hide commands
    ocp_pwd="${2:-$(${OC} whoami -t)}"
    cmd="${OC} login ${ocp_server} -u ${ocp_usr} -p ${ocp_pwd}"
    # Attempt to login up to 10 minutes
    watch_and_retry "$cmd" 10m
  )
}

# ------------------------------------------

# Function to delete all CRDs wich includes the input text on the current cluster
function delete_crds_by_name() {
  trap_to_debug_commands;

  # Input $1 : All CRDs to delete, by searching for *crd_regex*
  local crd_regex=$1

  local delete_crds=FALSE

  echo -e "\n# Searching for existing CRDs of previous ${crd_regex} installation on the cluster:"
  if ${OC} get crds |& highlight "${crd_regex}" ; then delete_crds=TRUE ; fi

  # If there are existing CRDs on the cluster - remove them all:
  # if [[ $? == 0 ]]; then
  if [[ "$delete_crds" == TRUE ]]; then
    echo -e "\n# Deleting ${crd_regex} CRDs in the cluster"
    crd_list=$(${OC} get crds -o name | grep -Po "\/\K.*${crd_regex}.*")
    # # Ignoring hanged CRDs on delete, due to K8s bug: https://github.com/kubernetes/kubernetes/issues/60538
    # ${OC} delete --timeout=1m crds $crd_list --ignore-not-found || : # || : to ignore none-zero exit code

    for crd_name in $crd_list ; do
      echo -e "\n# Deleting CRD $crd_name"
      ${OC} delete --timeout=1m crd "$crd_name" --ignore-not-found || \
      ${OC} patch "crd/${crd_name}" -p '{"metadata":{"finalizers":[]}}' --type=merge || :
    done

  else
    echo -e "\n# No CRD with '${crd_regex}' was found in the current cluster"
  fi

}


# ------------------------------------------

# Function to force delete a namespace
function force_delete_namespace() {
  trap_to_debug_commands;
  # Input $1 : Namespace to delete
  local ns_name="$1"

  # Input $2 (Optional) : Timeout to wait before forcing namespace deletion
  local delete_timeout="${2:-30s}"

  if [[ ${ns_name} == "default" ]] ; then
    echo -e "\n# Skipping namespace deletion, since it's the \"default\" namespace."
    return
  fi

  echo -e "\n# Show all resources (and OLMs) in namespace ${ns_name} to be deleted:"
  # ${OC} get all,olm --all-namespaces | grep --color "${crd_name}" || delete_namespace=FALSE
  ${OC} get all,olm -n "${ns_name}" |& highlight "No resources found" || :

  TITLE "Deleting whole namespace ${ns_name} from the cluster"

  ${OC} delete --timeout="$delete_timeout" namespace "${ns_name}" --ignore-not-found || force_ns_delete=TRUE

  if [[ "$force_ns_delete" == TRUE && $(${OC} get namespace "${ns_name}") ]]; then
    echo -e "\n# Warning: Force delete of namespace via API"
    ${OC} proxy &
    ${OC} get namespace "${ns_name}" -o json | jq '.spec = {"finalizers":[]}' > temp.json
    curl -k -H "Content-Type: application/json" -X PUT --data-binary @temp.json "127.0.0.1:8001/api/v1/namespaces/${ns_name}/finalize"
    kill -9 %% || :
    ${OC} delete namespace "${ns_name}" --ignore-not-found --grace-period=0 --force --wait || :
  fi

}

# ------------------------------------------

function create_docker_registry_secret() {
### Helper function to add new Docker registry
  trap '' DEBUG # DONT trap_to_debug_commands

  # input variables
  local registry_server="$1"
  local registry_usr=$2
  local registry_pwd=$3
  local namespace="$4"

  local secret_name="${registry_server}-${registry_usr}"
  # Replace anything but letters and numbers with "-"
  local secret_name="${secret_name//[^a-zA-Z0-9]/-}"

  TITLE "Creating new docker-registry in '$namespace' namespace
  Server: ${registry_server}
  Secret name: ${secret_name}"

  create_namespace "${namespace}"

  ${OC} delete secret "$secret_name" -n "$namespace" --ignore-not-found || :

  ( # subshell to hide commands
    ${OC} create secret docker-registry -n "${namespace}" "$secret_name" --docker-server="${registry_server}" \
    --docker-username="${registry_usr}" --docker-password="${registry_pwd}" # --docker-email=${registry_email}
  )

  echo -e "\n# Adding '$secret_name' secret:"
  ${OC} describe secret "$secret_name" -n "$namespace" || :

  ( # update the cluster global pull-secret
    ${OC} patch secret/pull-secret -n openshift-config -p \
    '{"data":{".dockerconfigjson":"'"$( \
    ${OC} get secret/pull-secret -n openshift-config --output="jsonpath={.data.\.dockerconfigjson}" \
    | base64 --decode | jq -r -c '.auths |= . + '"$( \
    ${OC} get "secret/${secret_name}" -n "$namespace"    --output="jsonpath={.data.\.dockerconfigjson}" \
    | base64 --decode | jq -r -c '.auths')"'' | base64 -w 0)"'"}}'
  )

  ${OC} describe secret/pull-secret -n openshift-config

}

# ------------------------------------------

# Function to install and expose Nginx service on the current KUBECONFIG cluster
function install_nginx_service() {
  trap_to_debug_commands;

  local ngnix_name="${1:-NginX}"
  local nginx_image="${2:-quay.io/openshifttest/nginx-alpine:latest}"

  local target_namespace="$3" # The Namespace for Ngnix
  local service_params="$4" # e.g. to expose Nginx as headless service on port 8080 pass: --port=8080 --cluster-ip=None

  if [[ -n "$target_namespace" ]] ; then
    echo -e "\n# Create Namespace for Nginx: $target_namespace"
    create_namespace "${target_namespace}"
  fi

  echo -e "\n# Delete and create Nginx Deployment: $target_namespace (using Nginx image \"$nginx_image\")"
  ${OC} delete deployment "${ngnix_name}" ${target_namespace:+-n $target_namespace} --ignore-not-found
  ${OC} create deployment "${ngnix_name}" ${target_namespace:+-n $target_namespace} --image="$nginx_image"

  echo -e "\n# Delete and expose Ngnix service:"
  ${OC} delete service "${ngnix_name}" ${target_namespace:+-n $target_namespace} --ignore-not-found
  ${OC} expose deployment "${ngnix_name}" --name="${ngnix_name}" ${service_params:+ $service_params} ${target_namespace:+-n $target_namespace}

  echo -e "\n# Wait 5 minutes for Ngnix service to be ready:"
  ${OC} rollout status --timeout=5m deployment "${ngnix_name}" ${target_namespace:+-n $target_namespace}
  ${OC} describe pod "${ngnix_name}" ${target_namespace:+-n $target_namespace}

}

# ------------------------------------------

# Function to create a namespace, if it does not exist
function create_namespace() {
  trap_to_debug_commands;

  local ns=$1
  # Create the namespace with the API directly
  echo -e "apiVersion: v1\nkind: Namespace\nmetadata:\n  name: ${ns}" | ${OC} apply -f -

  # TODO: Consider 'oc new-project' command:
  # ${OC} new-project "${SUBM_OPERATOR}" 2>/dev/null || ${OC} project "${SUBM_OPERATOR}" -q

}

# ------------------------------------------

# Function to get the cluster name from kubeconfig current-context
function print_current_cluster_name() {
  # Do not trap_to_debug_commands

  local current_context
  local cluster_name

  export KUBECONFIG="$KUBECONFIG"

  # Get cluster name of "admin" user in kubeconfig
  cluster_name=$(${OC} config view -o jsonpath='{.contexts[?(@.context.user == "admin")].context.cluster}' | awk '{print $1}' || :)

  # If it's empty, get the oldest cluster name found in kubeconfig
  if [[ -z "$cluster_name" ]] ; then
    cluster_name=$(${OC} config view -o jsonpath='{.clusters[-1].name}' | awk '{print $1}' || :)
  fi

  # If it's empty, get the cluster name of "admin" context
  if [[ -z "$cluster_name" ]] ; then
    cluster_name=$(${OC} config view -o jsonpath='{.contexts[?(@.name == "admin")].context.cluster}' | awk '{print $1}' || :)
  fi

  # If it's empty, get the cluster name of current context
  if [[ -z "$cluster_name" ]] ; then
    current_context=$(${OC} config current-context || :)
    cluster_name=$(${OC} config view -o jsonpath="{.contexts[?(@.name == '$current_context')].context.cluster}" || :)
  fi

  # Remove the :<port number> if exists
  cluster_name="${cluster_name%%:*}"
  # Replace anything but letters and numbers with "-"
  cluster_name="${cluster_name//[^a-zA-Z0-9]/-}"

  echo "$cluster_name"
}

# ------------------------------------------

# Function to print current cluster cloud name
function print_current_cluster_cloud() {

  # DONT trap_to_debug_commands

  local cluster_platform

  export KUBECONFIG="$KUBECONFIG"

  cluster_platform="$(${OC} get -o jsonpath='{.status.platform}{"\n"}' infrastructure cluster )" || :

  if [[ "$cluster_platform" == "AWS" ]] ; then
    echo "Amazon"
  elif [[ "$cluster_platform" == "GCP" ]] ; then
    echo "Google"
  elif [[ "$cluster_platform" == "OpenStack" ]] ;
    then echo "Openstack"
  else
    echo "Unknown"
  fi

}

# ------------------------------------------

# Function to print details of all used images in the running pods of a namespace
function print_images_info_of_namespace_pods() {
  # Do not trap_to_debug_commands

  local namespace=$1 # Default is current context namespace

  TITLE "Images of Pods ${namespace:+in namespace $namespace }"

  for img_id in $(${OC} get pods ${namespace:+-n $namespace} -o jsonpath="{..imageID}" \
  | tr -s '[[:space:]]' '\n' | sort | uniq -c | awk '{print $2}') ; do
  # for img in $(${OC} get images | awk '$0 ~ ENVIRON["REGISTRY_MIRROR"] { print $1 }') ; do
    print_image_info "$img_id" || continue
  done

}

# ------------------------------------------

# Function to print container details of an image
function print_image_info() {
  # Do not trap_to_debug_commands

  local img_id=$1
  local regex_container_info="\s+\K(name=|url=|version=|release=|build-date=).*"

  echo -e "\n### $(echo "$img_id" | sed -r 's|.*/([^@]+).*|\1|') Image ###"
  echo "id=${img_id}"

  # Get info from image if the original image id is accessible by url
  ${OC} image info "$img_id" 2>/dev/null | grep -Po "$regex_container_info" || IMG_INFO=FAILED

  if [[ "${IMG_INFO}" == FAILED ]] ; then
    # In there's no image info (e.g. no regestry access) - get the info from the local copy of the image
    img_id=$(echo "$img_id" | awk -F '@' '{print $2}') || :
    ${OC} describe image "$img_id" 2>/dev/null | grep -Po "$regex_container_info" || :
  fi

}

# ------------------------------------------

# Function to print details of all image tags info in namespace
function print_image_tags_info() {
  # Do not trap_to_debug_commands

  local namespace=$1 # Default is current context namespace
  local regex_container_info="\s+\K(name=|url=|version=|release=|build-date=).*"

  TITLE "ImageStream Tags ${namespace:+(in namespace $namespace) }"

  # Show image-stream tags
  ${OC} get istag ${namespace:+-n $namespace} | awk 'NR>1 {print $1}' | \
  while read -r img_tag ; do
    echo -e "\n### $(echo "$img_tag" | sed -r 's|.*/([^@]+).*|\1|') Image-Stream tag ###"
    ${OC} describe istag "$img_tag" ${namespace:+-n $namespace} 2>/dev/null \
    | grep -Po "$regex_container_info" || continue
  done

}

# ------------------------------------------

# Function to print hash details of all CSVs (Cluster service versions) in a namespace
function print_csvs_in_namespace() {
  # Do not trap_to_debug_commands, so it will not be printed as return value

  local namespace=$1 # Default is current context namespace

  TITLE "Cluster service versions (CSVs) ${namespace:+(in namespace $namespace) }"

  local csvs
  csvs="$(${OC} get csv ${namespace:+-n $namespace} -o name)"

  ${OC} get ${namespace:+-n $namespace} "$csvs" -o json \
  | jq -r '.spec.relatedImages[].image' | cut -d'/' -f2- | tr '/' '-'

}

# ------------------------------------------

# Function to return (print) the first running pod id, by a label. Exit with FATAL if nothing found.
function get_running_pod_by_label() {
  # Do not trap_to_debug_commands, so it will not be printed as return value
  local pod_label=$1
  local namespace=$2 # Optional: Namespace for the pod
  local tmp_file
  tmp_file="$(mktemp)_pod_status"

  # Wait up to 3 minutes for the pod to be ready
  ${OC} wait --timeout=3m --for=condition=ready pod ${namespace:+-n $namespace} -l "$pod_label" > "$tmp_file" || :
  pod_status="$(head -1 "$tmp_file" | awk -F '/| ' '{print $2}' | xargs)"

  # pod_id="$(${OC} get pod ${namespace:+-n $namespace} -l $pod_label --field-selector status.phase=Running | awk 'FNR == 2 {print $1}')"
  # Can also run with: -o jsonpath="{.items[0].metadata.name}"

  #if [[ -n "$(echo $pod_status)" && -n "$(echo $pod_id)" ]] ; then
  if [[ -n "$pod_status" ]]; then
    # echo "$pod_id"
    printf '%s' "$pod_status"
    return 0
  else
    # exit 1
    FAILURE "Pod '$pod_label' is not running in '${namespace:-default}' namespace. \n $pod_status"
  fi

}

# ------------------------------------------

function wait_for_all_nodes_ready() {
### function to wait for all nodes to be ready, with optional timeout duration
  trap_to_debug_commands;

  local duration=${1:-3m} # Default is 3 minutes

  ${OC} wait --timeout="$duration" --for=condition=ready nodes --all || nodes_status=DOWN
  ${OC} get nodes -o wide

  if [[ "$nodes_status" == DOWN ]] ; then
    FAILURE "Timeout (${duration}) exceeded while waiting for all nodes to be ready"
  fi

}

# ------------------------------------------

function wait_for_all_machines_ready() {
### function to wait for all Machine Configuration to be ready, with optional timeout duration
  trap_to_debug_commands

  local duration=${1:-20m} # Default is 20 minutes

  echo -e "\n# Wait up to $duration for Machine Config Daemon to be rolled out by openshift-machine-config-operator:"
  local cmd="${OC} rollout status --timeout=$duration ds -n openshift-machine-config-operator machine-config-daemon"
  watch_and_retry "$cmd" "$duration" || machines_status=DOWN

  echo -e "\n# Wait up to $duration for all Machines Config Pool to be updated:"
  cmd="${OC} wait --timeout=$duration --for condition=updated machineconfigpool --all"
  watch_and_retry "$cmd" "$duration" || machines_status=DOWN

  echo -e "\n# Status of Machine Config Pool:"
  ${OC} get machineconfigpool -o wide || machines_status=DOWN

  echo -e "\n# Status of Machine Config Operators:"
  ${OC} get all -n openshift-machine-config-operator -o wide || machines_status=DOWN

  echo -e "\n# Status of Daemon-Sets:"
  ${OC} get daemonsets -A -o wide || machines_status=DOWN

  if [[ "$machines_status" == DOWN ]] ; then
    FAILURE "Timeout (${duration}) exceeded while waiting for all Machine Configuration to be ready"
  fi

}

# ------------------------------------------

# Function to return (print) the all worker node ids, that have an external ip (nothing if none)
function get_worker_nodes_with_external_ip() {
  # Do not trap_to_debug_commands, so it will not be printed as return value
  ${OC} get nodes -l node-role.kubernetes.io/worker -o wide | awk '$7!="<none>" && NR>1 {print $1}' | grep .
}

# ------------------------------------------

# Function to return (print) all external ips of worker nodes (nothing if none)
function get_external_ips_of_worker_nodes() {
  # Do not trap_to_debug_commands, so it will not be printed as return value
  ${OC} get nodes -l node-role.kubernetes.io/worker -o wide | awk '$7!="<none>" && NR>1 {print $7}'
}

# ------------------------------------------

# Function to tail pod logs for N times, after each interval
function watch_pod_logs() {
  trap_to_debug_commands;

  local pod_to_watch="$1"
  local namespace="$2"
  local regex="$3"

  # Optional params:
  local retries=${4:-5}
  local interval=${5:-20s} # time between each retry attempt
  local tmp_file
  tmp_file="$(mktemp)_pod_log"
  local search_exit_code=0

  echo -e "# Tailing logs of Pod [$pod_to_watch] in Namespace [$namespace]: \n"

  cmd="${OC} logs --tail -1 --timestamps $pod_to_watch -n $namespace --all-containers --ignore-errors \
  > $tmp_file && grep -Ei '$regex' -m 1 -C 5 $tmp_file || sleep $interval"

  watch_and_retry "$cmd" "$retries" "$regex" || search_exit_code=$?

  if [[ "$search_exit_code" -ne 0 ]] ; then
    # print the log if pattern not found
    num_of_lines=$(wc -l < "$tmp_file")
    if (( num_of_lines > 100 )) ; then
      # crop 50 lines from head and tail, if num_of_lines larger than 100
      head -n 50 "$tmp_file"
      echo -e "\n...\n"
      tail -n 50 "$tmp_file"
    else
      cat "$tmp_file"
    fi
  fi

  return $search_exit_code
}

# ------------------------------------------

function print_pod_logs_in_namespace() {
  local namespace="$1"
  local pods_label="$2" # Optional: Select pods with this label only

  local cluster_name
  cluster_name="$(print_current_cluster_name || :)"

  TITLE "Pods descriptions and logs ${pods_label:+"by label: ${pods_label}," }in cluster: $cluster_name, namespace: $namespace"

  for pod in $(${OC} get pods ${pods_label:+ -l $pods_label} -n "$namespace" -o jsonpath='{.items[*].metadata.name}') ; do
    echo -e "\n### Pod $pod in cluster: $cluster_name, namespace: $namespace ###\n"
    ${OC} -n "$namespace" describe pod "$pod" || :
    ${OC} -n "$namespace" get pod "$pod" -o yaml || :

    if [[ "$(${OC} get pods -n "$namespace" "$pod" -o jsonpath='{.status.containerStatuses[*].ready}')" == true ]] ; then
      echo -e "\n### Active pod $pod logs ###\n"
      ${OC} -n "$namespace" logs "$pod" --timestamps --tail=500 --all-containers --ignore-errors || :
    else
      echo -e "\n### Terminated (previous) pod $pod logs ###\n"
      ${OC} -n "$namespace" logs -p "$pod" --timestamps --tail=500 --all-containers --ignore-errors || :
    fi
  done
}

# ------------------------------------------

function build_go_repo() {
### Pull and build a GO project from URL ###
  trap_to_debug_commands;

  local repo_url="${1#*://}" # For go get we need to trim the "https://"

  # Optional: branch or tag to pull (the default is latest branch)
  # local branch_or_tag=${2:+@$2}
  local branch_or_tag=${2}

  # local go_repo_and_branch="${repo_url}/...${branch_or_tag}"
  local go_repo_and_branch="${repo_url}/..."

  echo -e "\n# Downloading the repo [${go_repo_and_branch}] with GO: "
  # GO111MODULE="on" go get -v ${go_repo_and_branch} || echo -e "\n# 'go get ${go_repo_and_branch} might have had errors"
  GO111MODULE="off" go get -v "${go_repo_and_branch}" || echo -e "\n# GO get '${go_repo_and_branch}' might have had errors"

  local repo_local_path="$GOPATH/src/$repo_url"
  echo -e "\n# Pull latest changes with Git into: $repo_local_path"
  cd "$repo_local_path" || FAILURE "$repo_local_path was not created, exiting."

  git_reset_local_repo "${branch_or_tag}"

  echo -e "\n# Build the project with GO: "
  # make build # May fail if Docker is not pre-installed
  export GO111MODULE=on
  go mod vendor
  # go install -mod vendor # Compile binary and moves it to $GOBIN
  go build -mod vendor || echo -e "\n# No binary to compile in $repo_url"

  echo -e "\n# Project main directory content: "
  ls -la
}

# ------------------------------------------

# Function to fetch, reset and pull latest git repository (to be run inside local directory repo)
function git_reset_local_repo() {
  trap_to_debug_commands;

  # Optional param 2: another remote repository to pull from (e.g. fork)
  local forked_repo=${2}

  local remote_name="origin"

  if [[ -n "$forked_repo" ]] ; then
    remote_name="upstream"
    echo -e "\n# Add the a new remote '${remote_name}' to pull from: $forked_repo"
    git remote -v | grep -w ${remote_name} || git remote add ${remote_name} "${forked_repo}"
    git remote set-url ${remote_name} "${forked_repo}"
  fi

  # Optional param 1: branch or tag to pull (default is latest branch)
  local branch_or_tag=${1:-$(git remote show ${remote_name} | awk '/HEAD branch/ { print $3 }')}

  git config user.name 'Anonymous'
  git config user.email '<>'
  git config --get-all remote.${remote_name}.fetch
  git config --unset-all remote.${remote_name}.fetch
  git fetch --prune --all --tags
  git branch -m "${branch_or_tag}"
  # git branch -u ${remote_name} ${branch_or_tag}
  git remote set-branches --add ${remote_name} "${branch_or_tag}"
  # git fetch ${remote_name} ${branch_or_tag}
  # git reset --hard ${remote_name}/${branch_or_tag}
  # git checkout --theirs .
  git reset --hard "${branch_or_tag}"
  git pull -f ${remote_name} "${branch_or_tag}"

  echo -e "\n# Latest commits in the repository: \n"
  git log --date=short -10 --pretty="%C(Yellow)%h %x09 %C(reset)%ad %x09 %C(Cyan)%an: %x09 %C(reset)%s"

}

# ------------------------------------------

function get_latest_repository_version_by_tag() {
  ### Print Git repository tag, of the latest released version ###
  # Do not echo more info, since the output is the returned value

  local repo_url="$1"

  # Optional param: $2 => Search for branch tag that include this text.
  # If not specifying - it will search for the latest version tag (sorted by refname)
  local tag_to_search="$2"

  local regex="tags/\K.*${tag_to_search}.*"
  local branch_tag
  branch_tag="$(git ls-remote --tags "$repo_url" | sort -Vr -k2 | grep -Po -m 1 "$regex" || :)"

  [[ -n "$branch_tag" ]] || FAILURE "Git repository [${repo_url}] does not include any tag with \"tag_to_search\""

  echo "$branch_tag"
}

# ------------------------------------------

# Function to create test cases document in Polarion from Junit xml
function create_polarion_testcases_doc_from_junit() {
    trap '' DEBUG # DONT trap_to_debug_commands

    # Input (9 params) :

    local polarion_url="$1"
    local polarion_auth_file="$2" # Includes Polarion 'user:password' | base64 --wrap 0
    local junit_xml="$3"
    local polarion_project_id="$4"
    local polarion_team_name="$5"
    local polarion_user_name="$6"
    local polarion_component_id="$7"
    local polarion_testcases_doc=${8//[^a-zA-Z0-9 -]/_} # Replace special characters with underscore
    local polarion_test_plan_id="$9"

    local tc_list
    tc_list="$(mktemp)_testcases"

    local temp_test_output
    temp_test_output="$(mktemp)_test_output"

    TITLE "Creating Polarion test-cases document for Junit results: $junit_xml
    Polarion project: ${polarion_project_id}
    Document path: ${polarion_team_name}/${polarion_testcases_doc}"

    # Verify junit file exists
    [[ -s "$junit_xml" ]] || FAILURE "Failed to create Polarion test-cases file: '$junit_xml' is missing"

    echo -e "\n# Set output xml for Polarion test-cases"

    local testsuite_name
    testsuite_name=$(generate_suite_title_from_junit_filename "$junit_xml")

    local polarion_testcases_xml="${testsuite_name}_polarion_testcases.xml" # Append "polarion_testcases.xml"
    polarion_testcases_xml="$(dirname "${junit_xml}")/${polarion_testcases_xml}" # Append full directory path of the original junit_xml file

    echo -e "\n# Getting list of Test-Cases in format 'class-name.test-name' (without sh2ju test index): "
    grep '<testcase ' "$junit_xml" | \
    sed -r 's/.*name="([^"]+).*classname="([^"]+).*/\2.\1/ ; s/[0-9]+ : //' > "$tc_list"
    #sed -r 's/.*name="([^"]+).*classname="([^"]+).*/\2.\1/ ; s/ /_/g ; s/[0-9]+_:_//' > "$tc_list"

    cat "$tc_list"

    echo -e "<?xml version=\"1.0\" encoding=\"UTF-8\"?>  \n\
    <testcases project-id=\"${polarion_project_id}\" document-relative-path=\"${polarion_team_name}/${polarion_testcases_doc}\">  \n\
      <properties>  \n\
          <property name=\"lookup-method\" value=\"name\"/>  \n\
      </properties>" > "$polarion_testcases_xml"
      # Maybe required: <response-property name="${polarion_team_name}" value="testcase_importer"/>

    echo -e "\n# Injecting Polarion custom-fields for each test-case, into $polarion_testcases_xml"
    # TODO: This should rather be defined on external properties file:

    local current_script
    current_script="$(hostname) : $(realpath -s "${BASH_SOURCE[$i+1]}")"

    while read -r full_testcase_name ; do

      local class_name="${full_testcase_name%.*}" # text before the dot
      # local class_name="${testsuite_name}" # Making a common test suite across all imported junit files
      local test_name="${full_testcase_name#*.}" # text after the dot

      TITLE "Setting Polarion schema for a new Test Case:
      Junit source file: $junit_xml
      Test class name: ${class_name}
      Test case name [${test_name}]"

      echo -e "\n# Save <system-output> of junit testcase '${test_name}' into $temp_test_output"
      grep -zoP -m 1 "(?<=${test_name}\")(?s)[^\n]*${class_name}.*?(?=\</system-out)" "$junit_xml" > "$temp_test_output"

      echo -e "\n# Get testcase description headline, if defined within '###' tags"
      local testcase_headline
      testcase_headline="$(grep -ozP '(?<=### ).+\n?.*(?= ###)' "$temp_test_output")"
      [[ -n "$testcase_headline" ]] || testcase_headline="${testsuite_name}.${test_name}"

      echo -e "\n# Save all output lines starting with # as testcase description"
      local testcase_description
      testcase_description=$(sed -nr 's/^#+\s*([A-Z][^#]*)[\s#]*/\1/p' "$temp_test_output" | sed 's/\://g')

      echo -e "\n# Save all output lines starting with $ as testcase steps"
      local testcase_steps
      testcase_steps=$(sed -nr '/^\$ .*/p' "$temp_test_output")

      echo -e "\n# Crop 50 lines from head and tail, if number of lines in $temp_test_output is larger than 100"
      local num_of_lines
      num_of_lines=$(wc -l < "$temp_test_output")
      if (( num_of_lines > 100 )) ; then
        echo -e "$(head -n 50 "$temp_test_output") \
        \n...\n \
        $(tail -n 50 "$temp_test_output")" > "$temp_test_output"
      fi

      echo -e "\n# Remove everything before the <system-out>, and save as testcase_output"
      local testcase_output
      testcase_output="$(grep -zoP '<system-out>\K[\s\S]*' "${temp_test_output}" )"

      echo -e "\n# Add pre-line and replace all end of lines with <br> in testcase output"
      testcase_output="<br> <span style=\"white-space: pre-line\"> ${testcase_output//$'\n'/ <br>} </span>"

      echo -e "\n# Escape all < and > in testcase output"
      testcase_output="$(echo "${testcase_output}" | sed -e 's/</\&lt;/g' -e 's/>/\&gt;/g')"

      echo -e "\n# Create testcase title and description"

      echo "<testcase approver-ids=\"${polarion_user_name}:approved\" status-id=\"approved\" assignee-id=\"${polarion_user_name}\">
          <title>${testsuite_name}.${test_name}</title>
          <description>
            &lt;span style=\"font-size: 12pt; font-weight: bold;\"&gt; $testcase_headline &lt;/span&gt;
            &lt;ul&gt;
              " >> "$polarion_testcases_xml"

      echo "$testcase_description" | while read -r line ; do
        echo "&lt;li&gt; $line &lt;/li&gt;" >> "$polarion_testcases_xml"
      done

      echo "&lt;/ul&gt;
      </description>
      <test-steps>" >> "$polarion_testcases_xml"

      echo -e "\n# Create testcase steps"

      echo "$testcase_steps" | while read -r step ; do
        # echo "<test-step>
        # <test-step-column id=\"expectedResult\">...</test-step-column>
        echo "<test-step>
        <test-step-column id=\"step\"> $step </test-step-column>
        </test-step>
        " >> "$polarion_testcases_xml"
      done

      echo -e "\n# Close steps, and create testcase custom fields"

      echo "</test-steps>
      <custom-fields>
          <custom-field id=\"casecomponent\" content=\"${polarion_component_id}\" />
          <custom-field id=\"testtype\" content=\"functional\" />
          <custom-field id=\"caseimportance\" content=\"medium\" />
          <custom-field id=\"caselevel\" content=\"system\" />
          <custom-field id=\"caseposneg\" content=\"positive\" />
          <custom-field id=\"legacytest\" content=\"true\" />
          <custom-field id=\"caseautomation\" content=\"automated\" />
          <custom-field id=\"tcmsplan\" content=\"${polarion_test_plan_id}\" />
          <custom-field id=\"automation_script\">
            ${current_script} : ${testcase_output}
          </custom-field>
        </custom-fields>
    </testcase>
    " >> "$polarion_testcases_xml"
  done < "$tc_list"

      # More options:
      #
      # <custom-field id=\"setup\">
      #   &lt;span style=&quot;font-family: Verdana, Helvetica, sans serif; font-size: 11px; white-space: pre-line; color: black&quot;&gt;
      #    <![CDATA[ ${testcase_output} ]]>
      #   &lt;/span&gt;
      # </custom-field>
      #
      # <custom-field id=\"setup\">
      #   ${current_script} : <![CDATA[ ${testcase_output} ]]>
      # </custom-field>
      #
      #
      # <custom-field id=\"products\" content=\"ocp\" />
      # <custom-field id=\"subteam\" content=\"${polarion_team_name}\" />
      #
      # <custom-field id=\"legacytest\" content=\"true\" /> # Test needs at least one linked work item of type Requirement or be marked as a Legacy Test Case
      # <linked-work-items>
      #   <linked-work-item workitem-id=\"${full_testcase_name}\" lookup-method=\"name\" role-id=\"verifies\" />
      #   <linked-work-item workitem-id=\"${full_testcase_name}\" lookup-method=\"name\" role-id=\"derived_from\" />
      #   <linked-work-item workitem-id=\"${full_testcase_name}\" lookup-method=\"name\" role-id=\"refines\" />
      # </linked-work-items>
      echo "</testcases>" >> "$polarion_testcases_xml"

      echo -e "\n# Watch Polarion testcase-log status"
      local polarion_job_urls="$SCRIPT_DIR/polarion_testcases.url"
      watch_polarion_job_status "$polarion_url" "$polarion_auth_file" "testcase" "$polarion_testcases_xml" "$polarion_job_urls"
}


# ------------------------------------------

# Function to create Polarion test run (xml) from Junit
function create_polarion_testrun_result_from_junit() {
    trap '' DEBUG # DONT trap_to_debug_commands

    # Input (7 params) :

    local polarion_url="$1"
    local polarion_auth_file="$2" # Includes Polarion 'user:password' | base64 --wrap 0
    local junit_xml="$3"
    local polarion_project_id="$4"
    local polarion_team_name="$5"
    local polarion_testrun_template="$6"
    local polarion_test_plan_id="$7" # Optional: To set test plan (instead of the test plan from the testrun template)
    local polarion_include_skipped="$8" # Optional: If "true" - Display Junit skipped test as "Waiting" in Polarion (i.e. test not run yet)

    local sed_expression

    TITLE "Creating Polarion test-run from Junit file: $junit_xml"

    # Verify junit file exists
    [[ -s "$junit_xml" ]] || FAILURE "Failed to create Polarion test-run file: '$junit_xml' is missing."

    # ------------------------------------------------------------------------ #

    echo -e "\n# Set output xml for Polarion test-run results"

    local testsuite_name
    testsuite_name=$(generate_suite_title_from_junit_filename "$junit_xml")

    local polarion_testrun_xml="${testsuite_name}_polarion_testrun.xml" # Append "polarion_testrun.xml"
    polarion_testrun_xml="$(dirname "$junit_xml")/${polarion_testrun_xml}" # Append full directory path of the original junit_xml file

    # testsuite_name="$polarion_team_name Test Run - $(basename ${polarion_testrun_xml%%.*})"

    echo -e "\n# Set Polarion test-run ID with plain text only, and lowercase"
    local polarion_testrun_id
    polarion_testrun_id="${polarion_team_name//[^a-zA-Z0-9]/-}_${testsuite_name//[^a-zA-Z0-9]/-}"
    polarion_testrun_id="${polarion_testrun_id,,*}"

    # ------------------------------------------------------------------------ #

    TITLE "Generating Polarion Test-run file [${polarion_testrun_xml}] to import:

    Polarion Test Run ID: ${polarion_testrun_id}
    Polarion Project: ${polarion_project_id}
    Polarion Team: ${polarion_team_name}
    Polarion Test Suite: ${testsuite_name}
    Polarion Test Plan ID: ${polarion_test_plan_id}
    Polarion Test Run Template: ${polarion_testrun_template}
    Include Skipped Tests: ${polarion_include_skipped}
    "

    cp "$junit_xml" "$polarion_testrun_xml"

    echo -e "\n# Remove Test-Cases Junit index (if added within sh2ju): "
    sed -r 's/(<testcase.* name=")([0-9]+ : )(.*)/\1\3/' -i "$polarion_testrun_xml"

    echo -e "\n# Remove first <testsuiteS> tag (if exists)"
    sed -e '0,/<testsuites>/s/<testsuites>//' -i "$polarion_testrun_xml"
    # sed -r "s:<testsuites>::" -i "$polarion_testrun_xml"

    if [[ "$polarion_include_skipped" =~ ^(true|yes)$ ]]; then
      echo -e "\n# Display Junit skipped test as 'Waiting' in Polarion (i.e. test not run yet)"
      polarion_include_skipped="true"
    else
      polarion_include_skipped="false"
    fi

    # Define Polarion <testsuites> properties (it is passed into SED, make sure new lines ends with " \n\ ")
    polarion_suite_content="<testsuites> \n\
        <properties> \n\
            <property name=\"polarion-testrun-id\" value=\"${polarion_testrun_id}\" /> \n\
            <property name=\"polarion-testrun-title\" value=\"$testsuite_name\" /> \n\
            <property name=\"polarion-testrun-template-id\" value=\"$polarion_testrun_template\" /> \n\
            <property name=\"polarion-project-id\" value=\"$polarion_project_id\" /> \n\
            <property name=\"polarion-response-myteamsname\" value=\"$polarion_team_name\" /> \n\
            <property name=\"polarion-lookup-method\" value=\"name\" /> \n\
            ${polarion_test_plan_id:+<property name=\"polarion-custom-plannedin\" value=\"$polarion_test_plan_id\" />} \n\
            <property name=\"polarion-include-skipped\" value=\"${polarion_include_skipped}\" /> \n\
            <property name=\"polarion-create-defects\" value=\"true\" /> \n\
            <property name=\"polarion-testrun-status-id\" value=\"inprogress\" /> \n\
        </properties> \n\
    <testsuite "

    sed_expression="0,/<testsuite /s,<testsuite ,$polarion_suite_content,"

    # Insert this <testsuiteS> properties instead of the first <testsuite> tag:
    sed -r "$sed_expression" -i "$polarion_testrun_xml"

    # Remove last </testsuiteS> tag (if exists):
    sed -r -z "s:(.*)</testsuites>(.*):\1\2:" -i "$polarion_testrun_xml"

    # Add </testsuiteS> tag, after the last </testsuite> tag:
    sed -r -z 's:(.*</testsuite>):\1\n</testsuites>:' -i "$polarion_testrun_xml"

    # ------------------------------------------------------------------------ #
    #
    # This is commented out since Polarion Testcase verdict does not support rich text output
    #
    # echo -e "\n# Add rich text into each Test Case Verdict in $polarion_testrun_xml (change 'system-out' to 'polarion-testcase-comment')"
    #
    # # Define Polarion <testcase> property (it is passed into SED), make sure new lines ends with " \n\ ")
    #
    # sed_expression="\n\
    #     <properties> \n\
    #         <property name=\"polarion-testcase-comment\" value=\""
    #
    # sed -r "s:<system-out>:$sed_expression:g" -i "$polarion_testrun_xml"
    #
    # sed_expression="\" /> \n\
    #     </properties> \n"
    #
    # sed -r "s:</system-out>:$sed_expression:g" -i "$polarion_testrun_xml"
    #

    # ------------------------------------------------------------------------ #

    echo -e "\n# Add plain text into each Test Case Verdict in $polarion_testrun_xml (add 'polarion-testcase-comment'):"

    local testrun_comment="Auto generated ${BUILD_URL:+in Jenkins Build $BUILD_URL }from Junit file: $junit_xml"
    echo "$testrun_comment"

    # Define property of <testcase> comment in the test-run xml (it is passed into SED, make sure new lines ends with " \n\ ")
    local testcase_properties="\n\
        <properties> \n\
            <property name=\"polarion-testcase-comment\" value=\"${testrun_comment}\" /> \n\
        </properties> \n\
    </testcase>"

    sed_expression="s%</testcase>%${testcase_properties//%/\\%}%g"

    # Insert the property instead of EACH testcase tag
    sed -r "$sed_expression" -i "$polarion_testrun_xml"

    # ------------------------------------------------------------------------ #

    echo -e "\n# Add escaped HTML <br> tags at the end of all textual lines in $polarion_testrun_xml"

    local temp_testrun
    temp_testrun="$(mktemp)_testrun"

    awk '!/<|>|^\s*$/{$0=$0"&#xD;&#xA;&#13;"}1' "$polarion_testrun_xml" > "${temp_testrun}"

    mv "${temp_testrun}" "$polarion_testrun_xml"

    # ------------------------------------------------------------------------ #

    echo -e "\n# Update <testsuite name> to: $testsuite_name"

    sed -r "s/(testsuite name=\")([^\"]+)/\1${testsuite_name}/" -i "$polarion_testrun_xml"

    # ------------------------------------------------------------------------ #

    echo -e "\n# Update <classname> to: $testsuite_name"

    sed -r "s/(classname=\")([^\"]+)/\1${testsuite_name}/" -i "$polarion_testrun_xml"

    # ------------------------------------------------------------------------ #

    # Watch testcase-log web page
    local polarion_job_urls="$SCRIPT_DIR/polarion_testruns.url"
    watch_polarion_job_status "$polarion_url" "$polarion_auth_file" "xunit" "$polarion_testrun_xml" "$polarion_job_urls"

    local latest_job_url
    # Get the last non empty/whitespace row from $polarion_job_urls file
    latest_job_url="$(awk 'NF{p=$0}END{print p}' "$polarion_job_urls")"

    local cmd
    cmd="curl --config $polarion_auth_file -k ${latest_job_url}"

    local polarion_testrun_result_page
    polarion_testrun_result_page="$($cmd | awk -F'&#034;' '/testrun-url/ { print $4 }')"

    # Set link for all templates:
    all_templates_link="${polarion_url}/#/project/${polarion_project_id}/testruns?query=template.id%3A\"${polarion_testrun_template// /%20}\""

    # Set links for all titles:
    all_titles_link="${polarion_url}/#/project/${polarion_project_id}/testruns?query=title%3A\"${testsuite_name// /%20}\""

    TITLE "The new test-run result was successfully added to Polarion
    $polarion_testrun_result_page \n
    All test-runs by template-id '${polarion_testrun_template}':
    ${all_templates_link}
    All test-runs by title '${testsuite_name}':
    ${all_titles_link}"

}

# ------------------------------------------

# Function to create test cases document in Polarion from Junit xml
function generate_suite_title_from_junit_filename() {
    # Do not trap_to_debug_commands or echo, so it will not be printed as return value

    # Get file name without path and extension
    local testsuite_title
    testsuite_title="$(basename "${1%.*}")"

    # Remove all 'junit' substring from testsuite title
    testsuite_title="${testsuite_title//junit/}"

    # Remove leading and trailing non-alphabetic characters
    echo "$testsuite_title" | sed 's/^[^[:alnum:]]*//;s/[^[:alnum:]]*$//'
}

# ------------------------------------------

# Function to watch testcase-log or xunit-log web page, for "Message sent" (replace quotes special HTML characters to ASCII)
function watch_polarion_job_status() {
  trap '' DEBUG # DONT trap_to_debug_commands

  # Input params:
  local polarion_url="$1"
  local polarion_auth_file="$2" # Includes Polarion 'user:password' | base64 --wrap 0
  local polarion_import_type="$3" # "xunit" or "testcase"
  local polarion_import_file="$4" # filepath to import
  local polarion_job_urls="$5" # filepath to store all Polarion jobs' urls

  echo -e "\n# Import $polarion_import_type file [$polarion_import_file] into ${polarion_url}/import/${polarion_import_type} :\n"

  local polarion_log
  polarion_log="$(mktemp)_polarion_log"
  curl --config "$polarion_auth_file" -k -X POST -F file=@"${polarion_import_file}" "${polarion_url}/import/${polarion_import_type}" |& tee "$polarion_log"

  local polarion_job_id
  polarion_job_id=$(awk '/job-ids/ { print $4 }' "$polarion_log")

  if [[ -z "$polarion_job_id" ]] || [[ "$polarion_job_id" == 0 ]] ; then
    FAILURE "Error in the file or data to import to Polarion: $polarion_import_file"
  fi

  local polarion_job_url="${polarion_url}/import/${polarion_import_type}-log?jobId=${polarion_job_id}"
  echo -e "\n# Checking Polarion ${polarion_import_type} import job status at: $polarion_job_url"
  echo "$polarion_job_url" >> "$polarion_job_urls"

  local cmd="curl --config $polarion_auth_file -k $polarion_job_url | sed -r 's/&#034;|&#039;/\"/g' |& tee $polarion_log"
  local regex='Import.+Message sent'
  watch_and_retry "$cmd" 1m "$regex"

  if tail -n 10 "$polarion_log" | grep "failed" ; then
    FAILURE "Importing ${polarion_import_type} to Polarion did not complete successfully"
  fi
}

# ------------------------------------------

# Function to install "aha" - Ansi HTML Adapter - to convert text files to HTML
function install_aha() {
  # trap_to_debug_commands

  work_dir="$(echo "${1:-$PWD}" | tr -s /)" # Remove redundant slashes
  # TODO: Move $conda_install_dir to a common folder outside $work_dir
  # conda_install_dir="${work_dir}/miniconda"
  conda_install_dir="$(dirname "$work_dir")/miniconda"

  if [[ ! -x "$(command -v aha)" ]] ; then
    echo -e "\n# Installing Ansi HTML Adapter with Anaconda"
    install_anaconda "${work_dir}"
    install_conda_package "${conda_install_dir}" "aha" || CONDA_PKG=FAILED

    # If Conda install failed, try to compile aha binary from Git
    if [[ "$CONDA_PKG" == FAILED ]] ; then
      TITLE "Installing Ansi HTML Adapter with Anaconda failed - trying to compile aha binary from Git"

      local repo_url=https://github.com/theZiz/aha.git
      local repo_branch=0.5.1
      local repo_dir
      repo_dir=$(basename $repo_url .git)

      if [[ ! -x "$(command -v aha)" ]] ; then
        rm -rf "$repo_dir"
        # git clone --quiet --branch "$repo_branch" $repo_url > /dev/null
        git clone $repo_url --single-branch # --depth 1
        git --work-tree="$repo_dir"  --git-dir="$repo_dir"/.git checkout tags/$repo_branch
        # make -C "$repo_dir" &> /dev/null
        make install PREFIX="$GOBIN"
      fi
    fi
  fi

  aha --version
}

# ------------------------------------------

function log_to_html() {
  trap '' DEBUG # DONT trap_to_debug_commands

  # Input params:

  local log_file="$1"
  local title="${2:-${log_file%%.*}}" # html title (default is log filename)
  local html_output="${3:-${title//[ \/]/_}.html}" # html filename to create (default is title with underscores)
  local description="$4"

  TITLE "Generating HTML report from: $log_file"
  [[ -f $log_file ]] || FAILURE "The log file [${log_file}] does not exist or is inaccessible"

  install_aha "${WORKDIR}" || FAILURE "Ansi HTML Adapter tool is required to generate the report"

  # Set description as html headline, and replace end of lines with <br>
  [[ -z $description ]] || description="<h3> ${description//$'\n'/ <br>} </h3>"

  # Create HTML Header
  cat > "$html_output" <<EOF
  <?xml version="1.0" encoding="UTF-8" ?>
  <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
  <html xmlns="http://www.w3.org/1999/xhtml">
  <head>
  <meta http-equiv="Content-Type" content="application/xml+xhtml; charset=UTF-8; width=device-width; initial-scale=1" />
  <title>${title}</title>
  <style type="text/css">
  pre {white-space: pre-wrap; white-space: -moz-pre-wrap !important;
  white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;}
  .collapsible {
    background-color: LightSkyBlue;
    color: black;
    cursor: pointer;
    padding: 10px;
    width: 100%;
    border: none;
    text-align: left;
    outline: none;
    font-size: 20px;
    -webkit-touch-callout: text;
    -webkit-user-select: text;
    -khtml-user-select: text;
    -moz-user-select: text;
    -ms-user-select: text;
    user-select: text;
  }
  .active {
    background-color: RoyalBlue;
    color: white;
  }
  .collapsible:hover {
    background-color: RoyalBlue;
    color: white;
    text-decoration: underline;
  }
  .content {
    padding: 0 18px;
    display: none;
    overflow: hidden;
    background-color: LightSkyBlue;
  }
  </style>
  </head>
  <body style="background-color:LightSkyBlue">
  <header>
    <h1><b>${title}</b></h1>
    ${description}
  </header>
  <pre>
EOF

  # Trim empty lines (from top) and spaces (not tabs) from each line in the log file
  #sed '/\S/,$!d; s/^ \+//; s/ \+$//' -i $log_file
  sed '/\S/,$!d' -i "$log_file"

  # Create HTML content with Ansi HTML Adapter
  aha -f "$log_file" --title "$title" --word-wrap --no-header >> "$html_output"

  # Trim sh2ju debug lines starting with +++ from the html report
  sed -r '/^\s*\+\+\+/d' -i "$html_output"

  # Make all http urls as Html <a> hyperlinks
  sed -r "s#([^'\"])(https?://[^<> \t'\"]+)(\s|\n|$)# \1<a href='\2'>\2</a>\3 #g" -i "$html_output"

  # Replace all lines of "<span...### {text...} ###</span>" - with a collapsible span ("###" was created with "PROMPT" function)
  sed -r 's:<span.+###\s+:<button type="button" class="collapsible"><span>:g' -i "$html_output"
  sed -r 's:\s+###</span.+$:<\/span><\/button><div class="content">:g' -i "$html_output"

  # Close all collapsible spans, when getting to lines of ðŸŽ©ï¸Ž (excluding first time)
  sed -r 's:(.+ðŸŽ©ï¸Ž):<\/div><br><br>\1:g' -i "$html_output"
  sed '0,/<\/div><br><br>/s///' -i "$html_output"

  # Create HTML collapsible function (must be at the bottom)
  cat >> "$html_output" <<EOF
  </pre>
  <br><br><br>
  <script>
  var coll = document.getElementsByClassName("collapsible");
  var i;
  for (i = 0; i < coll.length; i++) {
    coll[i].addEventListener("click", function() {
      this.classList.toggle("active");
      var content = this.nextElementSibling;
      if (content.style.display === "block") {
        content.style.display = "none";
      } else {
        content.style.display = "block";
      }
    });
  }
  </script>
  </body>
  </html>
EOF

  echo -e "HTML report created:\n$html_output"
}
